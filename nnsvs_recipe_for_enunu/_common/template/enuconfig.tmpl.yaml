# Copyright (c) 2020 Ryuichi Yamamoto
# Copyright (c) 2020 oatsu
# Copyright (c) 2021 Tarou Shirani

# Is trained with ENUNU specific recipe
trained_for_enunu:        false
# Table (lyric -> phonemes) file path.
table_path:               "dic/kana2phonemes_utf8_for_enunu.table"
# bit depth of output wav file.
# 32 or 16 (recommended:32)
bit_depth:                32

defaults:
    - hydra/job_logging:  colorlog
    - hydra/hydra_logging: colorlog

verbose:                  100

# Setting for output WAV file.
sample_rate:              96000
gain_normalize:           true

# How was the model trained.
frame_period:             5
question_path:            "hed/{{question_path}}"
log_f0_conditioning:      true

# Use ground truth duration or not
# if true, time-lag and duration models will not be used.
ground_truth_duration:    false


# If not empty, try to search statisics in the directory
stats_dir:                "dump/{{spk}}/norm"
# If not empty, try to search models in the directory
model_dir:                "exp/{{spk}}_{{tag}}"

acoustic:
    question_path:        null
    checkpoint:           {{acoustic_eval_checkpoint}}
    in_scaler_path:       null
    out_scaler_path:      null
    # model_yaml:
    subphone_features:    "coarse_coding"
    relative_f0:          true
    post_filter:          true

duration:
    checkpoint:           {{duration_eval_checkpoint}}
    question_path:        null
    in_scaler_path:       null
    out_scaler_path:      null

timelag:
    question_path:        null
    checkpoint:           {{timelag_eval_checkpoint}}
    in_scaler_path:       null
    out_scaler_path:      null
    allowed_range:        {{timelag_allowed_range}}
    allowed_range_rest:   {{timelag_allowed_range_rest}}
